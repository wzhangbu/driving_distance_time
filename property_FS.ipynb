{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook is used to calculate the estimated distance and time from property to the firestation\n",
    "I use the following codes to set the environment. If you are using Image pr-home-ds-m340-ce, some packages are pre-installed.\n",
    "\n",
    "Env: conda create -n driving_distance python=3.12.11\\\n",
    "conda init bash \\\n",
    "source ~/.bashrc \\\n",
    "conda activate driving_distance\\\n",
    "<!---for read_data.py--->\n",
    "conda install -c conda-forge fsspec s3fs=2023.6.0 pyarrow tqdm scipy aiohttp \\\n",
    "<!---for ask_online.py--->\n",
    "conda install -c conda-forge pandas numpy boto3  requests geopy ipython \\\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The files directories are as follows:\\\n",
    "Firestations: s3://pr-home-datascience/DSwarehouse/Datasources/FireStationLocation/FireStation/FireStations_0.csv \\\n",
    "Properties: s3://pr-home-datascience/Users/test/IntermediateDrive/Quantarium/AD/good_address/rundt=202504/ \\\n",
    "\n",
    "We will read data from the directories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the libiaries and load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sagemaker-user/DRIVING_DISTANCE\n"
     ]
    }
   ],
   "source": [
    "# import the libiaries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import read_data\n",
    "import functions\n",
    "\n",
    "cwd = os.getcwd()\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, we are dealing with the data by states. Within the states, the properties are listed by neighbors. So a 300 batch of properties will usually give dozens of potential nearest fire stations, which we are able to submit them all to the OpenStreetMap website. If the number of potential fire stations exceeds 100, we may need to reduce the batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2851 firestations in NY. \n",
      "There are 6389671 properties in NY. \n"
     ]
    }
   ],
   "source": [
    "# The Paths and directories\n",
    "states = ['NY']\n",
    "#  CT, MA, NH, NJ, NY, PA\n",
    "\n",
    "\n",
    "FS_path = \"s3://pr-home-datascience/DSwarehouse/Datasources/FireStationLocation/FireStation/FireStations_0.csv\"\n",
    "\n",
    "# Use read_data.py to load the data\n",
    "for state in states:\n",
    "    property_path = \"s3://pr-home-datascience/Users/test/IntermediateDrive/Quantarium/AD/good_address/rundt=202504/\" + 'state='+states[0] + '/'\n",
    "    df_FS = read_data.ReadData(FS_path, state = state, directory=False)\n",
    "    df_property = read_data.ReadData(property_path, state=state, directory=True)\n",
    "    print(f'There are {len(df_FS.data)} firestations in {state}. ')\n",
    "    print(f'There are {len(df_property.data)} properties in {state}. ')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the keywords in the fire stations dataframe and properties dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2851 unique fire stations\n",
      "The fire station dataframe has keywords. \n",
      "Index(['OBJECTID', 'ID', 'NAME', 'TELEPHONE', 'ADDRESS', 'ADDRESS2', 'CITY',\n",
      "       'STATE', 'ZIP', 'ZIPP4', 'COUNTY', 'FIPS', 'DIRECTIONS', 'EMERGTITLE',\n",
      "       'EMERGTEL', 'EMERGEXT', 'CONTDATE', 'CONTHOW', 'GEODATE', 'GEOHOW',\n",
      "       'HSIPTHEMES', 'NAICSCODE', 'NAICSDESCR', 'GEOLINKID', 'X', 'Y',\n",
      "       'ST_VENDOR', 'ST_VERSION', 'GEOPREC', 'PHONELOC', 'QC_QA', 'STATE_ID',\n",
      "       'FDID', 'FRST_MBRS', 'EMS_MBRS', 'TOTALPERS', 'NUMTRKS', 'NUMABUL',\n",
      "       'TOTAL_VEHI', 'NBR_STA', 'OWNER', 'LEVEL_', 'TYPE', 'SPECIALTY',\n",
      "       'EMSLICENSE', 'EMERPHONE', 'EMS', 'PERM_ID', 'GNIS_ID', 'x2', 'y2'],\n",
      "      dtype='object')\n",
      "The property dataframe has keywords. \n",
      "Index(['QPID', 'State', 'PA_Latitude', 'PA_Longitude', 'Match_Code',\n",
      "       'Location_Code', 'add_check', 'geo_check', 'source', 'rundt', 'state'],\n",
      "      dtype='object')\n",
      "**************************\n",
      "The property data examples \n",
      "       QPID State  PA_Latitude  PA_Longitude  Match_Code Location_Code  \\\n",
      "0  42438566    NY      42.1019      -75.9244           1           AS0   \n",
      "1  77290598    NY      43.2056      -75.4574           1           AS0   \n",
      "2  77290611    NY      43.2060      -75.4380           1           AS0   \n",
      "3  77290612    NY      43.2056      -75.4379           1          AP02   \n",
      "4  77290613    NY      43.2056      -75.4379           1          AP02   \n",
      "\n",
      "  add_check geo_check  source   rundt state  \n",
      "0      good         Y       2  202504    NY  \n",
      "1      good         Y       2  202504    NY  \n",
      "2      good         Y       2  202504    NY  \n",
      "3      good         Y       2  202504    NY  \n",
      "4      good         Y       2  202504    NY  \n"
     ]
    }
   ],
   "source": [
    "print(f'There are {len(df_FS.data['ID'].unique())} unique fire stations')    \n",
    "print('The fire station dataframe has keywords. ')\n",
    "print(df_FS.data.keys())\n",
    "print('The property dataframe has keywords. ')\n",
    "print(df_property.data.keys())\n",
    "print('**************************')\n",
    "print('The property data examples ')\n",
    "print(df_property.data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the functions.py to request online\n",
    "Use the functions in the functions.py to calculate the distance and time from the properties to the nearest firestation.\\\n",
    "\n",
    "Please notice, we calcualte the routes to 5 nearest firestation by default and record the best route."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps:\\\n",
    "1: Set the state and output path\\\n",
    "2: Define chunk and batch size\\\n",
    "3: Loop through chunk indices (adjust range to control concurrent jobs)\\\n",
    "4: Run the routing process using the nearest 5 firestations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the functions in the functions.py to calculate the distance and time from the properties to the nearest firestation\n",
    "# Please notice, we calcualte the routes to 5 nearest firestation by default and record the best route.\n",
    "\n",
    "\n",
    "# Chunksize: 100000 for MA, 200000 for NJ, 300000 for NY, 300000 for other states.\n",
    "# We can just use 300,000 later.\n",
    "state = 'NY'\n",
    "output_path = \"./results/\" + state +'/'\n",
    "# or you can save it to Amazon S3\n",
    "# output_path = 's3://pr-home-datascience/Projects/AdHoc/InternProjects/2025/2025InternSummer Driving distance for Prospect Table/'+state+'/'\n",
    "\n",
    "\n",
    "# identify the total length, chunksize, and batchsize\n",
    "total = len(df_property.data)\n",
    "chunksize = 300000\n",
    "process_batch_size = 300\n",
    "num_chunks = (total + chunksize - 1) // chunksize\n",
    "\n",
    "# this for loop helps run concurrent jobs in the Pipelines\n",
    "# Change i to run the jobs concurrently\n",
    "for i in range(6, 10):\n",
    "    print(f'Now is running the batch {i}.\\n')\n",
    "    # start and end indices of the property \n",
    "    start = i * chunksize\n",
    "    end = min((i + 1) * chunksize, total)\n",
    "    df_chunk = df_property.data.iloc[start:end]\n",
    "\n",
    "    # process the chunk of properties\n",
    "    results_df = functions.process_all_batches(df_chunk, df_FS.data, batchsize=process_batch_size)\n",
    "    output_file_path = output_path +  f\"FS_batch_{i}_n{str(chunksize)}.csv\"\n",
    "\n",
    "    if len(results_df) == chunksize:\n",
    "        #  if all the batches give the correct results from OpenStreetMap\n",
    "        results_df.to_csv(output_file_path, index = False)\n",
    "        print(f'Finishing the writing file batch {i}.\\n')\n",
    "    else:\n",
    "        #  change file names if not all the batches give the correct results\n",
    "        output_file_path = output_path +  f\"FS_batch_{i}_n{str(chunksize)}_failed.csv\"\n",
    "        results_df.to_csv(output_file_path, index = False)\n",
    "        print(f'Missing data in the batch {i}.\\n')\n",
    "\n",
    " \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "driving_distance",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
